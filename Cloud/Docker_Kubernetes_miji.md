# Docker:whale:



## Docker?

> 컨테이너 기반의 오픈소스 가상화 플랫폼
>
> 다양한 프로그램, 실행환경을 컨테이너로 추상화하고 동일한 인터페이스를 제공하여 프로그램의 배포 및 관리를 단순하게 해줌



## Images?

- images: 컨테이너 실행에 필요한 파일과 설정값 등을 포함하는 것으로, 상태값을 가지지 않고 변하지 않음.

  - tar 파일을 묶어놓은 file system으로 Template같은 친구들

    이미지는 컨테이너를 실행하기 위한 **모오오오오든 정보**를 가지고 있기 때문에 더 이상 의존성 파일을 컴파일하고 이것저것 설치할 필요가 없음

  - 하지만 용량이 매우 커서 기존 이미지에 파일 하나 추가해서 수백메가를 다시 다운받는다면 매우 비효율적, 이런 문제를 해결하기 위해 **레이어(layer)**라는 개념을 사용하고 유니온 파일 시스템을 이용하여 여러 개의 레이어를 하나의 파일 시스템으로 사용할 수 있게 해줌.



## Container?

- Container: 이미지를 실행한 상태이며 추가되거나 변하는 겂은 컨테이너에 저장(가상화 기술 중 하나)
  - 단 컨테이너 삭제하면 내부 데이터도 삭제. 이를 해결하기 위해 `Volumn`을 사용

> 기존 가상화 방식: *OS를 가상화* (우리에게 익숙한 [VMware](http://www.vmware.com/)나 [VirtualBox](https://www.virtualbox.org/)같은 가상머신은 호스트 OS위에 게스트 OS 전체를 가상화하여 사용하는 방식)

- 이러한 상황을 개선하기 위해 CPU의 가상화 기술([HVM](https://en.wikipedia.org/wiki/Hardware-assisted_virtualization))을 이용한 [KVM](http://www.linux-kvm.org/)Kernel-based Virtual Machine과 [반가상화](https://en.wikipedia.org/wiki/Paravirtualization) Paravirtualization방식의 [Xen](https://www.xenproject.org/)이 등장
  - ex)  [OpenStack](https://www.openstack.org/)이나 AWS, [Rackspace](https://www.rackspace.com/)같은 클라우드 서비스에서 가상 컴퓨팅 기술의 기반
- 기존 가상화 기술보다 가벼워지고 이식성이 뛰어남. 가상머신보다 공간을 덜 차지하며 더 많은 응용 프로그램을 처리할 수 있음
- 하지만 보안 문제에서 일부 사람들은 컨테이너가 응용 프로그램이 공유하는 OS가 하나만 있고 가상머신이 응용 프로그램뿐만 아니라 OS도 격리하기 때문에 컨테이너가 하이퍼 바이저보다 덜 안전하다고 생각. -> 두가지 모두 혼용하여 사용하는 것이 더 좋음



<img src="https://subicura.com/assets/article_images/2017-01-19-docker-guide-for-beginners-1/vm-vs-docker.png" style="zoom:50%;" />





### Docker Container Environment

- 도커 컨테이너 클러스터 관리 기능
  - 쿠버네티스 기반 도커 클러스터 관리
  - 도커 클러스터 라이프 사이클 관리
- 포드 관리 및 외부 서비스 제공
  - 포드 라이프 사이클 관리
  - 이미지 저장소 가능
  - 

- 로드 밸런서: 대규모로 들어오는 트래픽을 여러 대의 VM으로 분산 처리하여 서버부하, 접속속도 저하 등의 문제점들을 해결하기 위한 기능
- Openstack: 클라우드 환경에 대한 모든 타입을 지원하는 오픈소스 클라우드 컴퓨팅 플랫폼
  - 사용자의 요구사항에 따라 클라우드 구성요소를 선택하여 최적화된 환경 구축 용이
  - 대시보드를 통해 전체 데이터 센터 관리





>  토폴로지는 컴퓨터 네트워크의 요소들(링크, 노드 등)을 물리적으로 연결해 놓은 것, 또는 그 연결 방식을 말한다.

- 네트워크 토폴로지  제공
- Auto-Scaling: 로드 밸런서와 연동, CPU/DISK/Network 사용량 기준의 임계치 이상 사용 시 자동 서버 확장



## Kubernetes?:whale2:

> 리눅스 컨테이너 작업을 자동화하는 오픈소스 플랫폼

> Docker Container 운영을 자동화 하기 위한 컨테이너 오케스트레이션 툴 (즉 컨테이너를 쉽고 빠르게 배포/ 확장)

- 확장성: 

- 유연성: 로컬 테스트, 프로덕트 운영이든 환경에 상관없이 사용자의 복잡한 니즈를 모두 수용할 수 있는 유연성을 가짐

- 이식성: 온프레미스(*소프트웨어를 서버에 직접 설치해 쓰는 방식*), 하이브리드 또는 퍼블릭 클라우드 인프라스트럭처등 여러 환경에서 기동됨

- docker swarm: docker 컨테이너를 클러스터링 하고 예약하는 도구

- | **차이점**             | **Kubernetes**                                               | **Docker Swarm**                                             |
  | ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | **응용 프로그램 배포** | 마이크로서비스 및 pod 를 이용하여 배포                       | 스웜 클러스터에서 마이크로 서비스만 사용 가능 다중컨테이너는 yaml 파일을 통해 설치가능 |
  | **확장성**             | 분산시스템에서 작업시, 올인원 작동 이에따라 컨테이너 확장 및 배포가 느려짐 | k8s 보다 컨테이너로 배포 할 수 있어 확장에 대하여 빠름       |
  | **네트워킹**           | pod 통신으로 서로 상호 작용할 수 있음                        | 도커 브릿지 네트워크를 사용, 이를 통해 사용자는 컨테이너 데이터 트래픽을 암호화 하여 생성 가능 |
  | **부하 분산**          | pod 는 서비스를 통해 노출 되어 로드밸런서로 구현이 가능      | 서비스사 자동으로 할당 되거나 사용자가 미리 지정한 포트에서 작동 |
  | **확장**               | 자동으로 확장기능                                            | 자동 확장 기능을 사용하지 않는다                             |
  | **로깅 및 모니터링**   | 프로세를 관리 하는 도구를 제공                               | 로깅 및 모니터링을 위해 도구를 사용할 필요없음               |

- scale out: 서버의 수를 늘려 능력을 향상시키는 것. 다수의 처리를 병행적으로 실시해야 하는 경우에 적합.

- 애플리케이션의 확장과 장애 조치를 처리하고, 배포 패턴 등을 제공.

- 쿠버네티스는:

  - **서비스 디스커버리와 로드밸런싱 제공**: 컨테이너에 대한 트래픽이 많으면, 쿠버네티스는 네트워크 트래픽을 로드밸런싱하고 배포하여 배포가 안정적으로 이루어질 수 있음
  - **스토리지 오케스트레이션 제공**: 쿠버네티스를 사용하면 로컬 저장소, 공용 클라우드 공급자 등과 같이 원하는 저장소 시스템을 자동으로 탑재 할 수 있음
  - **자동화된 롤아웃과 롤백 제공**: 배포된 컨테이너의 원하는 상태를 서술할 수 있으며 현재 상태를 원하는 상태로 설정하는 속도에 따라 변경 가능.
  - **자동화된 빈 패킹(bin packing) 제공**:  컨테이너화된 작업을 실행하는데 사용할 수 있는 쿠버네티스 클러스터 노드를 제공. 각 컨테이너가 필요로 하는 CPU와 메모리(RAM)를 쿠버네티스에게 지시. 쿠버네티스는 컨테이너를 노드에 맞추어서 리소스를 가장 잘 사용할 수 있도록 해줌
  - **자동화된 복구(self-healing) 제공**: 쿠버네티스는 실패한 컨테이너를 다시 시작하고, 컨테이너를 교체하며, '사용자 정의 상태 검사'에 응답하지 않는 컨테이너를 죽이고, 서비스 준비가 끝날 때까지 그러한 과정을 클라이언트에 보여주지 않음.
  - **시크릿과 구성 관리 제공**:  쿠버네티스를 사용하면 암호, OAuth 토큰 및 SSH 키와 같은 중요한 정보를 저장하고 관리 할 수 있음. 컨테이너 이미지를 재구성하지 않고 스택 구성에 시크릿을 노출하지 않고도 시크릿 및 애플리케이션 구성을 배포 및 업데이트 할 수 있음.

- Ingress: 클러스터 내의 서비스에 대한 외부 접근을 관리하는 API 오브젝트. 일반적으로 HTTP를 관리함.



#### :star:Docker: microservice를 컨테이너화 하는 플랫폼

#### :star:Kubernetes: 컨테이너화 한 어플리케이션을 여러 서버에 배포할 때 관리를 수월하게 할 수 있게 함으로써 도커 워크로드를 다룰 수 있게 해주는 시스템



### Kubernetes Component:electric_plug:

> 쿠버네티스를 배포하면 클러스터를 얻고 클러스터는 컨테이너화된 애플리케이션을 실행하는 노드(쿠버네티스의 작업 장비(worker machine))라고 하는 워커 머신의 집합니다. 최소 한개의 워커 노드를 가진다.

![](https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg)



- worker node는 애플리케이션의 구성요소인 pod를 호슼트
- 컨트롤 플레인(*컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어*) worker node와 클러스터 내 pod를 관리
  - 클러스터 내 어떠한 머신에서든지 동작할 수 있으나 간결성을 위하여 구성 스크립트는 보통 동일 머신 상에 모든 컨트롤 플레인 컴포넌트를 구동시키고, 사용자 컨테이너는 해당 머신 상에 동작시키지 않음.
- **kube-apiserver**: 쿠버네티스 API 서버(*쿠버네티스 API를 노출하는 쿠버네티스 [컨트롤 플레인](https://kubernetes.io/ko/docs/reference/glossary/?all=true#term-control-plane) 컴포넌트*, *클러스터의 다른 부분 그리고 외부 컴포넌트가 서로 통신할 수 있도록 HTTP API를 제공*)의 주요 구현
  - 수평으로 확장 가능
  - 여러 kube-apiserver 인스턴스를 실행하고, 인스턴스간의 트랙픽을 균형있게 조정할 수 있음
- **etcd**: 모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성·고가용성 키-값 저장소
  - 저장소로 사용하게 된다면 백업 필수
- **kube-scheduler**: node가 배정되지 않은 새로 생성된 pod를 감지하고, 실행할 노드를 선택하는 컨트롤 컴포넌트
- **kube-controller-manager**: 컨트롤러를 구동하는 마스터 상의 컴포넌트
- **cloud-controller-manager**: 클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트
  - 클라우드 제공자 전용 컨트롤러만 실행
  - 자신의 사내 또는 PC 내부의 학습 환경에서 쿠버네티스를 실행 중인 경우 클러스터에는 클라우드 컨트롤러 매니저가 없음



## 이전/현재 배포 방식:older_man:

- 전통적인 배포: 애플리케이션을 물리 서버에서 실행
  - 리소스 할당 문제 발생, 다른 애플리케이션 성능 저하
- 가상화된 배포: 단일 물리 서버의 CPU에서 여러 가상 시스템(VM)을 실행할 수 있게 함
  - 가상화 사용 시 VM간에 애플리케이션을 격리하고 애플리케이션의 정보를 다른 애플리케이션에서 자유롭게 액세스 할 수 없으므로 일정 수준의 보안성 제공
  - 리소스를 보다 효율적으로 사용 가능
  - 하드웨어 비용 절감 및 물리 리소스를 폐기 가능한 가상 머신으로 구성된 클러스터로 만들 수 있음
- 컨테이너 개발:  VM과 유사하지만 격리 속성을 완화하여 애플리케이션 간에 운영체제(OS)를 공유
  - 가벼움
  - 컨테이너에는 자체 파일 시스템, CPU 점유율, 메모리, 프로세스 공간 등이 있음
  - 이미지 생성 및 배포가 쉬움
  - 개발과 운영의 관심사 분리
  - 지속적 개발, 통합 및 배포 가능
  - 클라우드 및 OS 배포판 간 이식성



## Hypervisor? :high_brightness:

> 호스트 컴퓨터에서 다수의 운영 체제를 동시에 실행하기 위한 논리적 플랫폼

- 게스트 운영 체제에 가상 운영 플랫폼을 제공하면서 게스트 운영 체제를 관리

- 단일 하드웨어에서 여러 다른 가상 머신을 호스팅할 수 있는 프로그램

- 시스템에서 호스트 하드웨어의 프로세서, 메모리 및 리소스가 있는 것처럼 보이기 때문에 이러한 가상 머신 또는 운영 체제 각각은 자체 프로그램을 실행할 수 있음. 그러나 실제로 이러한 리소스를 가상 시스템에 할당하는 것은 **하이퍼바이저**

- 하이퍼 바이저를 사용하면 여러 컴퓨터가 단일 컴퓨터 하드웨어에서 최적으로 작동하도록 할 수 있음

- 서버에 있는 모든 물리적 장치/메모리와 디스크에 액세스 가능. 가상 머신의 모든 측면과 부분을 제어할 수 있음

  ![](http://cloudrain21.com/wordpress/wp-content/uploads/2019/08/docker-container-9-638.jpg)

- 하이퍼바이저의 위치와 역할에 따른 분류:

  - ![](https://upload.wikimedia.org/wikipedia/commons/e/e1/Hyperviseur.png)

  - Type1: 'Native' 또는 'Bare Metal'형 하이퍼바이저

    - > 호스트 하드웨어에 직접 설치하여 구동

    - 하드웨어 바로 위에 설치

    - 하드웨어를 제어하는 OS 역할과 VM들을 관리하는 역할을 모두 하이퍼바이저가 담당

    - *Windows나 Linux를 설치하듯이, 아무 것도 설치되어 있지 않은 컴퓨터에 하이퍼바이저를 설치*

    - ex) Microsoft Hyper-V의 경우 OS를 설치하면 기본으로 제공되기 때문에 Hyper-V 다운로드가 필요하지 않고 해당 옵션을 활성화시키는 방식으로 사용할 수 있음.

    - 가상화 방식: 전가상화(Full Virtualization)와 반가상화(Para-Virtualization)

  - Type2: 'Hosted' 하이퍼바이저

    - > 호스트 OS위에 설치되는 방식의 하이퍼바이저

    - 기존의 컴퓨터 환경을 그대로 사용하는 방식이므로 설치 및 구성이 편리

    - ![](http://cloudrain21.com/wordpress/wp-content/uploads/2019/08/vbox.jpg)

    - 하이퍼바이저가 하드웨어 바로 위에서 위치하는 것이 아니라 *Host OS* 위에 위치함

    - 한단계의 Layer를 더 타야하기 때문에 성능 관점에서 보면 type1이 type2보다 유리한 면이 있음

    - ex) VMware Workstation, VMware Player, VirtualBox



- ​	

## Microservice?:milky_way:

> 모놀리식: 소프트웨어의 모든 구성요소가 한 프로젝트에 통합 된 형태
>
> ​	단점: 일정 규모 이상 서비스가 커지고 많은 개발자가 투입 시, 시스템 구조 파악, 빌드 시간, 테스트 시간, 서비스 부분적 scale-out 어려움

![](http://192.168.100.42:12346/uploads/images/gallery/2020-08/scaled-1680-/%EB%AA%A8%EB%86%80%EB%A6%AC%EC%8B%9D,%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%97.PNG)



> 마이크로 서비스: 모든 요소를 하나의 애플리케이션에 구축하는 전통적인 모놀리식이 아닌 모든 요소가 독립적이며 연동되어 동일한 태스크를 완수하는 구성요소 또는 프로세스

- 장점: 
  - 배포 관점:
    - 서비스별 개별 배포 가능(배포 시 전체 서비스 중단하지 않음)
    - 요구사항을 신속하게 반영하여 빠르게 배포 가능
  - 확장 관점:
    - 특정 서비스에 대한 확장이 용이
    - 클라우드 사용에 적합한 아키테쳐
  - 장애 관점:
    - 장애가 전체 서비스로 확장될 가능성이 적음
    - 부분 장애에 대한 쉬움
    - 신기술 적용에 유용
- 단점:
  - MSA는 모놀리식보다 복잡한 아키텍처로 전체 서비스가 커짐에 따라 복잡도가 증가
  - 서비스간 호출 시 API를 사용하여 비용과 응답 지연 시간이 증가
  - 서비스가 분리되어 테스트와 트랜잭션의 복잡도가 증가, 많은 자원이 필요
  - 데이터가 여러 서비스에 걸쳐 분산되기 때문에 한번에 조회하기 어렵고 데이터의 정합성 관리가 어려움



## HPC?:desktop_computer:

> 방대한 양의 데이터를 분석하여 가치 있는 정보를 생산하고 복잡한 연산을 빠르게 해결하기 위해 대규모 컴퓨팅 서비스



## 가상화?

> 단일 물리 노드의 자원을 논리적으로 분리하여 다수의 가상 머신을 제공하는 기술



## 역가상화?

> 다수의 노드의 CPU, 메모리 등의 하드웨어 자원을 통합하여 논리적 형태의 단일 서버로 제공하는 기술



## 하이퍼 기술?

> 하드웨어 자원을 역가상화하여 네트워크 기반의 자원 통합을 위한 기능을 제공하는 커널



## 단일 가상화 클러스터?

> 소프트웨어 정의 서버를 구성하는 물리 노드들로 구성된 클러스터



## 통합 자원 공유 풀(Unified Resource Sharing Pool)?

> 하이퍼 커널을 통해 가상화된 자원을 통합적으로 등록 및 관리하기 위한 운영 풀



## 리소스 어그리게이터(Resource Aggregator)?

> 단일 가상화 클러스터 중 운영체제가 설치되어 접근 가능한 노드



## 리소스 프로바이더(Resource Provider)?

> 운영체제 설치 없이 노드가 보유한 하드웨어 자원을 제공하는 노드



## 컴퓨터 아키텍쳐 종류:office:

- 선점형 VM: 일괄 처리 작업 및 내결함성 작업 부하의 컴퓨팅 인스턴스를 위한 아키텍처
- 어플리케이션 확장: 자동 확장, 백업 헤드, 모니터링, 경고 구성요소를 추가하는 참조 아키텍처
- 온프레미스 버스트: 온프레미스 작업 부하를 클라우드 서비스에 적용하고 통합